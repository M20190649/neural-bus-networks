{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Knet,Compat,Interact,Plots;\n",
    "include(\"../julia/format_data.jl\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# file, training_proportion, num_input_stops, stops_ahead_to_predict, stops_to_predict\n",
    "routes = get_routes(\"../data/full_routes.mat\",0.8,10,1,1);\n",
    "\n",
    "x_train  = routes[\"train_input_data\"];\n",
    "y_train = routes[\"train_output_data\"];\n",
    "x_test = routes[\"test_input_data\"];\n",
    "y_test = routes[\"test_output_data\"];\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = (x_train .- mean(x_train,2))./std(x_train,2)\n",
    "x_test = (x_test .- mean(x_test,2))./std(x_test,2)\n",
    "size(x_train),\n",
    "size(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function predict(w,x)\n",
    "    for i=1:2:length(w)\n",
    "        # w is a vector of weight matrices\n",
    "        x = w[i]*x .+ w[i+1]\n",
    "        if i<length(w)-1\n",
    "            # Apply ReLU nonlinearity\n",
    "            x = max.(0,x)\n",
    "        end\n",
    "    end\n",
    "    return x\n",
    "end\n",
    "\n",
    "loss(w,x,y)=0.5*(sum((y-predict(w,x)).^2) / size(x,2))\n",
    "\n",
    "lossgradient = grad(loss);\n",
    "\n",
    "function train(w, dtrn; lr=.5, epochs=10)\n",
    "    for epoch=1:epochs\n",
    "        for (x,y) in dtrn\n",
    "            g = lossgradient(w, x, y)\n",
    "            for i in 1:length(w)\n",
    "                axpy!(-lr, g[i], w[i])\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "    return w\n",
    "end\n",
    "\n",
    "function weights(h)\n",
    "    w = Any[]\n",
    "    x = 10\n",
    "    for y in h\n",
    "        push!(w,0.1*randn(y,x))\n",
    "        push!(w, zeros(y, 1))\n",
    "        x = y\n",
    "    end\n",
    "    return w\n",
    "end\n",
    "\n",
    "\n",
    "function accuracy(w, dtst, pred=predict)\n",
    "    s = 0\n",
    "    n = 0\n",
    "    s_resid = 0\n",
    "    yvar = var(y_test)\n",
    "    for (x, ygold) in dtst\n",
    "        ypred = pred(w, x)\n",
    "        s+= sum(abs.(ypred - ygold))\n",
    "        s_resid += (ypred - ygold).^2\n",
    "        n+=1\n",
    "    end\n",
    "    s_tot =yvar*n\n",
    "    return (s/n,1-s_resid/(s_tot))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function main()\n",
    "    hidden_layer_sizes = [100,100,1]\n",
    "    w = weights(hidden_layer_sizes)\n",
    "    dtrn = zip([x_train[:,i] for i in 1:size(x_train,2)],y_train)\n",
    "    dtst = zip([x_test[:,i] for i in 1:size(x_test,2)],y_test)\n",
    "    report(epoch)=println((epoch,\"Train MAE: \",accuracy(w,dtrn),\"Test MAE: \",accuracy(w,dtst)))\n",
    "    report(0)\n",
    "    epochs = 5\n",
    "    learning_rate = 0.001\n",
    "    @time for epoch=1:epochs\n",
    "        train(w, dtrn; lr=learning_rate, epochs=1)\n",
    "        report(epoch)\n",
    "#       gradcheck(loss, w, first(dtrn)...; gcheck=o[:gcheck], verbose=true)\n",
    "    end\n",
    "    return w\n",
    "end\n",
    "\n",
    "main();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "@manipulate for i = 1:10\n",
    "println(x_train[:,i])\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_layer_sizes = [200,100,100,1]\n",
    "w1 = weights(hidden_layer_sizes)\n",
    "x = [1 2 3 4 5 6 7 8 9 10]\n",
    "predict(w1,x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@manipulate for i = 1:10\n",
    "histogram(x_train[i,:])\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histogram(y_train')\n",
    "# mean(y_train)\n",
    "# sqrt(var(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://arxiv.org/pdf/1407.5949.pdf\n",
    "function lstm(weight,bias,hidden,cell,input)\n",
    "    gates   = hcat(input,hidden) * weight .+ bias\n",
    "    hsize   = size(hidden,2)\n",
    "    forget  = sigm(gates[:,1:hsize])\n",
    "    ingate  = sigm(gates[:,1+hsize:2hsize])\n",
    "    outgate = sigm(gates[:,1+2hsize:3hsize])\n",
    "    change  = tanh(gates[:,1+3hsize:end])\n",
    "    cell    = cell .* forget + ingate .* change\n",
    "    hidden  = outgate .* tanh(cell)\n",
    "    return (hidden,cell)\n",
    "end\n",
    "\n",
    "function initmodel(atype, hidden, vocab, embed)\n",
    "    init(d...)=atype(xavier(d...))\n",
    "    \n",
    "    bias(d...)=atype(zeros(d...))\n",
    "    model = Array(Any, 2*length(hidden)+3)\n",
    "    X = embed\n",
    "    for k = 1:length(hidden)\n",
    "        H = hidden[k]\n",
    "        model[2k-1] = init(X+H, 4H)\n",
    "        model[2k] = bias(1, 4H)\n",
    "        model[2k][1:H] = 1 # forget gate bias = 1\n",
    "        X = H\n",
    "    end\n",
    "    model[end-2] = init(vocab,embed)\n",
    "    model[end-1] = init(hidden[end],vocab)\n",
    "    model[end] = bias(1,vocab)\n",
    "    return model\n",
    "end\n",
    "\n",
    "let blank = nothing; global initstate\n",
    "function initstate(model, batch)\n",
    "    nlayers = div(length(model)-3,2)\n",
    "    state = Array(Any, 2*nlayers)\n",
    "    for k = 1:nlayers\n",
    "        bias = model[2k]\n",
    "        hidden = div(length(bias),4)\n",
    "        if typeof(blank)!=typeof(bias) || size(blank)!=(batch,hidden)\n",
    "            blank = fill!(similar(bias, batch, hidden),0)\n",
    "        end\n",
    "        state[2k-1] = state[2k] = blank\n",
    "    end\n",
    "    return state\n",
    "end\n",
    "end\n",
    "\n",
    "function predict(model, state, input; pdrop=0)\n",
    "    nlayers = div(length(model)-3,2)\n",
    "    newstate = similar(state)\n",
    "    for k = 1:nlayers\n",
    "        input = dropout(input, pdrop)\n",
    "        \n",
    "        (newstate[2k-1],newstate[2k]) = lstm(model[2k-1],model[2k],state[2k-1],state[2k],input)\n",
    "        input = newstate[2k-1]\n",
    "    end\n",
    "    return input,newstate\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.6.0",
   "language": "julia",
   "name": "julia-0.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
