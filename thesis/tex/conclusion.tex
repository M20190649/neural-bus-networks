\chapter{Conclusion}

Traffic networks are notoriously difficult to model, and classical methods struggle to capture high levels of variation in the network.
Most techniques for predicting arrival times are moving from deterministic to learning based algorithms.
The explosion in the amount of data available in traffic networks now allows larger, more accurate models of traffic.
These models can be used to generate predictions and deliver these predictions to passengers, decreasing wait times and increasing the overall efficiency of the network.
Additionally, the increase in available data necessitates larger models and new architectures.
This research analyzed the effectiveness of the three most common neural network architectures and found that recurrent neural networks show the best accuracy.

\section{Implications}

\subsection{Neural networks can handle the high volume of data generated by traffic networks}

One issue with using larger models is overfitting.
Linear models limit the variance of the estimator class, improving the generalization of the model.
However this research shows that neural networks models can combine several different data sources and pull out relevant features, with little overfitting.
The models in this research do overfit to some extent, but their generalization scores are better than the linear model, despite the models having an extremely high variance.
In particular, the CNN trained in this research improved almost two-fold compared to the linear model, with around a thousand-fold increase in the number of parameters.
This may indicate that even larger models may be effective at traffic prediction.
Traffic networks generate huge amounts of data, especially given the advent of mobile apps such as Google Maps and Waze.
All of this data can be leveraged to improve the operating efficiency of the network.
The streaming nature of this data makes neural network models suitable.

\subsection{Recurrent neural networks are effective at modeling bus time series data}

Traffic networks generate time series data, which are well modeled by RNNs.
Feed forward models like MLPs and CNNs do a good job of feature extraction and pattern recognition, however their ability to model trends is limited.
CNNs can do 1D convolutions which model time series data to some extent, however they cannot remember long term patterns.
This is where RNNs can shine.
This research shows that RNNs outperform feed forward networks on traffic modeling tasks.
Traffic networks have a lot of latent state which cannot be directly measured.
For example the data used in this research does not have any passenger counts, which are vital to estimating dwell time at each stop.
However RNNs can model latent features like this over long and short time periods.
This may be an underlying reason for their effectiveness.

\section{Contributions}

In summary, in this thesis I:

\begin{enumerate}
\item Used MBTA GPS data from buses to model their trajectories over a 3 year period
\item Processed the GPS data to extract high level features such as arrival times at stops and wait times at each stop
\item Gathered more data related to modeling the traffic network such as traffic estimates and bus metadata
\item Used all of the processed data to train a series of models including linear, MLP, CNN and RNN
\item Generated predictions with these models and showed that neural networks can generate accurate predictions of travel times
\item Showed that large feed forward models can generate highly accurate predictions without overfitting
\item Showed that RNNs outperform feed forward models
\item Gave an explanation for this improvement based on time series analysis and latent variables
\end{enumerate}

